seed: ${..seed}
algo: HANDEM

load_path: ${..checkpoint} # path to the checkpoint to load

handem:
  output_name: 'debug'
  normalize_input: True
  normalize_value: True
  value_bootstrap: True
  num_actors: ${...task.env.numEnvs}
  normalize_advantage: True
  asymmetric: True
  gamma: 0.99
  tau: 0.95
  learning_rate: 5e-4
  kl_threshold: 0.016
  # PPO batch collection
  horizon_length: 8
  minibatch_size: 32768
  discriminator_minibatch_size: 
  regressor_minibatch_size: 32768
  regressor_learning_rate: 5e-4
  actor_mini_epochs: 5
  critic_mini_epochs: 8
  # PPO loss setting
  clip_value: True
  entropy_coef: 0.0
  e_clip: 0.2
  bounds_loss_coef: 0.0001
  # grad clipping
  truncate_grads: True
  grad_norm: 1.0
  # snapshot setting
  save_best_after: 0
  save_frequency: 50
  max_agent_steps: 200000000
  ppo_network:
    mlp:
      actor_units: [512, 512, 256, 128]
      critic_units: [512, 512, 256, 128]
  discriminator_network:
    discriminator_epochs: 5
    arch: 'transformer' # 'mlp' or 'transformer'
    mlp:
      units: [256, 128]
    transformer:
      n_layer: 3
      n_head: 3
      n_embd: 32
      dropout: 0.0
  reconstruction_network:
    autoregressive: False
    arch: 'mlp' # 'mlp' or 'transformer'
    regressor_epochs: 5
    mlp:
      units: [256, 256]
    transformer:
      n_layer: 4
      n_head: 3
      n_embd: 32
      dropout: 0.0
    vertex_dim: 2
